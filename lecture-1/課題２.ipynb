{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c469737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: https://github.com/google?type=all&sort=updated\n",
      "\n",
      "Fetching page 1: https://github.com/google?type=all&sort=updated\n",
      "Found 16 repositories on this page.\n",
      "Sample: [{'name': 'material-design-icons', 'language': None, 'stars': 52600}, {'name': 'guava', 'language': 'Java', 'stars': 51300}, {'name': 'zx', 'language': 'JavaScript', 'stars': 44900}]\n",
      "\n",
      "Total repositories processed: 16\n",
      "\n",
      "Saved repositories (sorted by stars desc):\n",
      "- material-design-icons | (unknown) | 52600 stars\n",
      "- guava | Java | 51300 stars\n",
      "- zx | JavaScript | 44900 stars\n",
      "- styleguide | HTML | 38700 stars\n",
      "- leveldb | C++ | 38400 stars\n",
      "- googletest | C++ | 37500 stars\n",
      "- XNNPACK | C | 2179 stars\n",
      "- nomulus | Java | 1767 stars\n",
      "- xls | C++ | 1374 stars\n",
      "- site-kit-wp | JavaScript | 1337 stars\n",
      "- heir | C++ | 609 stars\n",
      "- osv-scalibr | Go | 536 stars\n",
      "- toucan | C++ | 48 stars\n",
      "- open-dice | C++ | 26 stars\n",
      "- dive | C++ | 17 stars\n",
      "- chromium-policy-vulnfeed | Go | 7 stars\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import sqlite3\n",
    "import re\n",
    "import sys\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "BASE_URL = \"https://github.com\"\n",
    "ORG_URL = \"https://github.com/google?type=all&sort=updated\"\n",
    "DB_PATH = \"課題.db\"\n",
    "# 一般的なブラウザ UA（ブロック回避のため強めのUA）\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 \"\n",
    "        \"(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "    ),\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9,ja;q=0.8\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\",\n",
    "}\n",
    "def parse_star_count(text):\n",
    "    \"\"\"\n",
    "    '1.2k', '3M', '1,234' のような GitHub のスター表記を整数へ変換。\n",
    "    \"\"\"\n",
    "    text = text.strip().lower()\n",
    "    if not text:\n",
    "        return 0\n",
    "    text = text.replace(\",\", \"\")  # \"1,234\" => \"1234\"\n",
    "    m = re.match(r\"^([\\d\\.]+)\\s*([km]?)$\", text)\n",
    "    if not m:\n",
    "        try:\n",
    "            return int(text)\n",
    "        except ValueError:\n",
    "            return 0\n",
    "    num = float(m.group(1))\n",
    "    suffix = m.group(2)\n",
    "    if suffix == \"k\":\n",
    "        return int(num * 1_000)\n",
    "    if suffix == \"m\":\n",
    "        return int(num * 1_000_000)\n",
    "    return int(num)\n",
    "def get_soup(url):\n",
    "    \"\"\"\n",
    "    URLからHTMLを取得してBeautifulSoupを返す。各取得後にtime.sleep(1)を必ず実施。\n",
    "    \"\"\"\n",
    "    resp = requests.get(url, headers=HEADERS, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    # 取得HTMLがSPA等で内容薄い場合の簡易チェック（必要ならログ）\n",
    "    html = resp.text\n",
    "    time.sleep(1)  # polite delay\n",
    "    return BeautifulSoup(html, \"html.parser\")\n",
    "def extract_repos_from_page(soup):\n",
    "    \"\"\"\n",
    "    組織のリポジトリ一覧ページから\n",
    "    {name, language, stars} の辞書リストを抽出。\n",
    "    HTML構造変化に備えて複数のフォールバックセレクタを使用。\n",
    "    \"\"\"\n",
    "    repos = []\n",
    "    # コンテナ（新UIで使われることがある）\n",
    "    container = soup.select_one('div[data-testid=\"results-list\"]')\n",
    "    if container:\n",
    "        cards = container.select('li, div.Box-row')\n",
    "    else:\n",
    "        # 旧UI・一般フォールバック\n",
    "        cards = soup.select('li[itemprop=\"owns\"], div.Box-row, li')\n",
    "    for card in cards:\n",
    "        # リポジトリ名の抽出\n",
    "        name = None\n",
    "        # 最も確実：org名を含むリンク\n",
    "        name_link = card.select_one('a[href^=\"/google/\"]')\n",
    "        if not name_link:\n",
    "            # フォールバック\n",
    "            name_link = card.select_one('a[itemprop=\"name codeRepository\"], h3 a, a[data-hovercard-type=\"repository\"]')\n",
    "        if name_link:\n",
    "            text = name_link.get_text(strip=True)\n",
    "            # \"google/guava\" の場合は末尾要素をリポジトリ名に\n",
    "            parts = [p for p in text.split('/') if p]\n",
    "            name = parts[-1] if parts else text\n",
    "        # 主要言語\n",
    "        language = None\n",
    "        lang_el = card.select_one('span[itemprop=\"programmingLanguage\"]')\n",
    "        if lang_el:\n",
    "            language = lang_el.get_text(strip=True)\n",
    "        else:\n",
    "            # 言語色ドット隣や補助テキストの候補\n",
    "            lang_candidates = card.select(\n",
    "                '.f6 .mt-2 span, '\n",
    "                '.mr-3 .text-bold, '\n",
    "                'span[data-testid=\"repo-language-color\"] + span, '\n",
    "                'li.d-inline span'\n",
    "            )\n",
    "            for c in lang_candidates:\n",
    "                t = c.get_text(strip=True)\n",
    "                # ノイズ除去\n",
    "                if t and len(t) <= 30 and not any(x in t.lower() for x in [\"updated\", \"star\", \"fork\", \"issue\"]):\n",
    "                    language = t\n",
    "                    break\n",
    "        # スター数\n",
    "        stars = 0\n",
    "        star_link = card.select_one('a[href$=\"/stargazers\"]')\n",
    "        if star_link:\n",
    "            stars = parse_star_count(star_link.get_text(strip=True))\n",
    "        if name:\n",
    "            repos.append({\"name\": name, \"language\": language if language else None, \"stars\": stars})\n",
    "    return repos\n",
    "def find_next_page(soup):\n",
    "    \"\"\"\n",
    "    ページネーションの「次へ」を見つけてURLを返す。\n",
    "    ない場合はNone。\n",
    "    \"\"\"\n",
    "    next_link = soup.select_one('a.next_page, a[rel=\"next\"]')\n",
    "    if not next_link:\n",
    "        # テキストベースのフォールバック\n",
    "        for a in soup.select('a'):\n",
    "            if a.get_text(strip=True).lower() in (\"next\", \"older\"):\n",
    "                next_link = a\n",
    "                break\n",
    "    if next_link and next_link.get(\"href\"):\n",
    "        return urljoin(BASE_URL, next_link[\"href\"])\n",
    "    return None\n",
    "def init_db(conn):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS repositories (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            name TEXT NOT NULL,\n",
    "            language TEXT,\n",
    "            stars INTEGER NOT NULL,\n",
    "            UNIQUE(name)\n",
    "        );\n",
    "    \"\"\")\n",
    "    # よく使う並び替え・フィルタ用のインデックス（任意）\n",
    "    cur.execute(\"CREATE INDEX IF NOT EXISTS idx_repositories_stars ON repositories(stars);\")\n",
    "    cur.execute(\"CREATE INDEX IF NOT EXISTS idx_repositories_language ON repositories(language);\")\n",
    "    conn.commit()\n",
    "def save_repos(conn, repos):\n",
    "    cur = conn.cursor()\n",
    "    for r in repos:\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO repositories (name, language, stars)\n",
    "            VALUES (?, ?, ?)\n",
    "            ON CONFLICT(name) DO UPDATE SET\n",
    "                language = excluded.language,\n",
    "                stars    = excluded.stars;\n",
    "        \"\"\", (r[\"name\"], r[\"language\"], r[\"stars\"]))\n",
    "    conn.commit()\n",
    "def show_saved(conn):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT name, language, stars\n",
    "        FROM repositories\n",
    "        ORDER BY stars DESC, name ASC;\n",
    "    \"\"\")\n",
    "    rows = cur.fetchall()\n",
    "    print(\"\\nSaved repositories (sorted by stars desc):\")\n",
    "    if not rows:\n",
    "        print(\"- no rows -\")\n",
    "    for name, language, stars in rows:\n",
    "        print(f\"- {name} | {language if language else '(unknown)'} | {stars} stars\")\n",
    "def main():\n",
    "    print(f\"Target: {ORG_URL}\")\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    try:\n",
    "        init_db(conn)\n",
    "        url = ORG_URL\n",
    "        total = 0\n",
    "        page_idx = 1\n",
    "        while url:\n",
    "            print(f\"\\nFetching page {page_idx}: {url}\")\n",
    "            try:\n",
    "                soup = get_soup(url)\n",
    "            except requests.HTTPError as e:\n",
    "                print(f\"HTTP error: {e}\", file=sys.stderr)\n",
    "                break\n",
    "            except requests.RequestException as e:\n",
    "                print(f\"Request error: {e}\", file=sys.stderr)\n",
    "                break\n",
    "            repos = extract_repos_from_page(soup)\n",
    "            print(f\"Found {len(repos)} repositories on this page.\")\n",
    "            if repos:\n",
    "                # サンプルを表示\n",
    "                print(\"Sample:\", repos[:3])\n",
    "            else:\n",
    "                # デバッグ用にページタイトルや一部テキストを表示\n",
    "                title = soup.title.get_text(strip=True) if soup.title else \"(no title)\"\n",
    "                print(f\"Page title: {title}\")\n",
    "                first_text = soup.get_text(\" \", strip=True)[:500]\n",
    "                print(f\"Page snippet: {first_text}\")\n",
    "            save_repos(conn, repos)\n",
    "            total += len(repos)\n",
    "            next_url = find_next_page(soup)\n",
    "            if next_url and next_url != url:\n",
    "                url = next_url\n",
    "                page_idx += 1#\n",
    "            else:\n",
    "                url = None  # 次ページなしで終了\n",
    "        print(f\"\\nTotal repositories processed: {total}\")\n",
    "        show_saved(conn)\n",
    "    finally:\n",
    "        conn.close()\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
